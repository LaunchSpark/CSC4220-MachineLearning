{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as poly\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient_descent(coef, x_start, learning_rate, num_iterations):\n",
    "    \"\"\"\n",
    "    f: function to minimize\n",
    "    df: derivative of f\n",
    "    x_start: starting point\n",
    "    learning_rate: step size\n",
    "    num_iterations: number of iterations to run\n",
    "    \n",
    "    Returns: (x_history, f_history) - lists of x values and f(x) values\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    # delete this and the following line in your implementation. (do not delete the return)\n",
    "    f = poly.Polynomial(coef)\n",
    "    df = f.deriv()\n",
    "    x_history = [x_start]\n",
    "    f_history = [f(x_start)]\n",
    "\n",
    "    x = x_start\n",
    "    for i in range(num_iterations):\n",
    "        x -= learning_rate * float(df(x))\n",
    "        x_history.append(float(x))\n",
    "        f_history.append(float(f(x)))\n",
    "\n",
    "    return x_history, f_history\n",
    "\n",
    "\n",
    "# function2(x) = x^2 - 12x + 4\n",
    "coef_f2 = [4, -12, 1]\n",
    "learning_rates = [0.01, 0.1, 0.5, 0.9]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "results = {}\n",
    "for lr in learning_rates:\n",
    "    x_hist, f_hist = gradient_descent(coef_f2, x_start=0.0, learning_rate=lr, num_iterations=100)\n",
    "    results[lr] = (x_hist, f_hist)\n",
    "    plt.plot(range(len(f_hist)), f_hist, linewidth=2, label=f\"α = {lr}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Gradient Descent Convergence for Different Learning Rates\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print final values again for convenience\n",
    "for lr in learning_rates:\n",
    "    x_hist, f_hist = results[lr]\n",
    "    print(f\"α = {lr:0.2f} | final x = {x_hist[-1]:.10f} | final f(x) = {f_hist[-1]:.10f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12f0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
